# 知识点复习

## redis优化

①容量控制
压缩value、设置过期时间、存储热数据
②热key倾斜
保证key的随机性，保证hash值的随机分布，控制热点key并发问题（限流降级、本地缓存）
③集群过大
避免集群节点过多，根据业务对集群进行拆分

雪球开源RDB分析工具RDR
https://github.com/xueqiu/rdr
分析Redis快照情况，包括：Redis不同结构类型容量、key数量、top 100 largest keys、前缀key数量和容量

## mysql复习

## Tomcat相关

### 1.加大内存（调优）
heap size 默认 1/64 - 1/4 不要超过80%
heap space 存放类实例
PermGen space 内存永久区 存放class和meta信息 （GC过程不会被清理，jvm默认设置4M ）

JAVA_OPTS="-server-Xms800m-Xmx800m-XX:PermSize=64M-XX:MaxNewSize=256m-XX:MaxPermSize=128m-Djava.awt.headless=true"

### 2.加大连接数（调优）
<Connector/>
minProcessors\maxProcessors\acceptCount(最大连接数，受限于操作系统的内核)\connectionTimeout
<Connectorport="8080"
maxThreads="150"minSpareThreads="25"maxSpareThreads="75"
enableLookups="false"redirectPort="8443"acceptCount="100"
debug="0"connectionTimeout="20000"
disableUploadTimeout="true"/>

### 3.tomcat部署
①conf配置
``` xml
<host/>
<Context path="/hello"
docBase="D:/eclipse3.2.2/forwebtoolsworkspacehello/WebRoot"deb
ug="0"
privileged="true">
</Context>
```  
②放置在webapps目录

### 4.处理性能
①加大jvm内存    
②服务器资源（CPU、内存、硬盘）影响
	CPU：影响高并发
	内存：大量数据处理
	硬盘：读写性能  
③nginx缓存服务器、tomcat集群共享session  

## JVM性能优化
### ①Java内存泄漏：
#### 长生命周期对象持有短生命周期对象引用
栈弹出方法：
``` java
public Object pop() {
	if (size == 0)
    	throw new EmptyStackException();
	Object result = elements[--size];
	// 消除过期的引用,不会导致内存泄漏
    elements[size] = null; 

	return result;
}
```
当类中持有过期的元素的引用时，就有可能造成内存泄露问题。而且通常这种内存泄露问题都是我们无意识造成的，逻辑上我们认为弹出的元素就应该被GC回收掉，但事实上GC没有办法回收，因此elements数组依然持有它。这种问题很隐蔽，通常只要类自己管理内存（如类中有一个Array或List型的结构），那么我们就应该警惕内存泄露的问题。

> 扩展：
> WeakHashMap ： 自清理的机制，非线程安全，优化程度（HashMap在Jdk8做了好多优化，比如单链表在过长时会转化为红黑树，降低极端情况下的操作复杂度）
> WeakHashMap的使用场景：1.阿里开源的Java诊断工具Arthas中使用了WeakHashMap做类-字节码的缓存 2.cache 3.ThreadLocal中用ThreadLocalMap存储Thread对象，ThreadLocalMap也利用到了WeakReference的特性

#### 内存泄露的常见来源之一是监听器和其他回调。
如果你实现了一个API，客户端在这个API中注册回调，却没有显式地取消注册，那么除非你采取某些动作，否则他们就会积聚。确保回调立即被当成垃圾回收的最佳方法是只保存它们的弱引用（weak reference），例如，只将它们保存成WeakHashMap中的键。

#### 对于已经加入HashSet的对象，如果修改参与计算HashCode的属性的信息，会导致删除该HashSet中的该对象无效，从而导致内存泄漏。

HashSet：采用哈希算法存取对象集合，它内部采用对某个数字进行取余的方式进行分组和划分对象的存储区域。Object对象中的hashCode方法返回每个对象哈希码，但从某个HashSet中找对象时，会调用HashCode去获得该对象的哈希码，然后定位到相对应的区域，取出该区域的对象然后调用equals方法进行对比，然后做判断。


## 深拷贝和浅拷贝

> 浅拷贝只复制指向某个对象的指针，而不复制对象本身，新旧对象还是共享同一块内存。 但深拷贝会另外创造一个一模一样的对象，新对象跟原对象不共享内存，修改新对象不会改到原对象。 当我们把一个对象赋值给一个新的变量时， 赋的其实是该对象的在栈中的地址，而不是堆中的数据 。 也就是两个对象指向的是同一个存储空间，无论哪个对象发生改变，其实都是改变的存储空间的内容，因此，两个对象是联动的。 浅拷贝是按位拷贝对象， 它会创建一个新对象 ，这个对象有着原始对象属性值的一份精确拷贝。 如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型），拷贝的就是内存地址 ，因此如果其中一个对象改变了这个地址，就会影响到另一个对象。

创建对象的5种方式

①、通过 new 关键字
②、通过 Class 类的 newInstance() 方法 / 通过 Constructor 类的 newInstance 方法
③、利用 Clone 方法  【深拷贝和浅拷贝】
④、反序列化
序列化是把堆内存中的 Java 对象数据，通过某种方式把对象存储到磁盘文件中或者传递给其他网络节点（在网络上传输）。而反序列化则是把磁盘文件中的对象数据或者把网络节点上的对象数据，恢复成Java对象模型的过程。
``` java
Object obj = new Object();
Person p2 = (Person) Class.forName("com.ys.test.Person").newInstance();
Person p3 = (Person) Person.class.getConstructors()[0].newInstance();
Person p4 = (Person) p3.clone();
```

Object 类提供的 clone 是只能实现 浅拷贝的。

调用对象的 clone 方法，必须要让类实现 Cloneable 接口，并且覆写 clone 方法。

深拷贝
1.调用对象的 clone 方法，必须要让类实现 Cloneable 接口，并且覆写 clone 方法。 
不太可取
2.利用序列化
每个需要序列化的类都要实现 Serializable 接口，如果有某个属性不需要序列化，可以将其声明为 transient，即将其排除在克隆属性之外。

``` java
public Object deepClone() throws Exception{
    // 序列化
    ByteArrayOutputStream bos = new ByteArrayOutputStream();
    ObjectOutputStream oos = new ObjectOutputStream(bos);

    oos.writeObject(this);

    // 反序列化
    ByteArrayInputStream bis = new ByteArrayInputStream(bos.toByteArray());
    ObjectInputStream ois = new ObjectInputStream(bis);

    return ois.readObject();
}
```

